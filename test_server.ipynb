{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load test model\n",
    "clf = joblib.load('classify_test.model') # 분류기 엔진\n",
    "cate_dict = joblib.load('cate_dict.dat') # id별 카테고리가 맵핑되어있는 파일\n",
    "vectorizer = joblib.load('vectorizer_test.dat') # 제목들을 숫자 id로 변환해주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cate_id_name_dict = dict(map(lambda (k,v):(v,k),cate_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['size.dat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize size\n",
    "size = 0\n",
    "joblib.dump(size,'size.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define removeStopWords\n",
    "\n",
    "mapping = { 'A/S':'AS'}\n",
    "stop_words = [u\"%즉시할인쿠폰\",  u\"5% 즉시할인\", u\"0% 즉시할인\", u\"% 즉시할인\", u\"5% 할인\", u\"0% 할인\", u\"5%할인\", u\"0%할인\", u\"% 할인\", u\"적립\",\n",
    "              u\"쿠폰\", u\"즉시\",u\"정품\", u\"증정\", u\"할인\",\n",
    "              u\"해외직배송\", u\"직배송\", u\"무료배송\", u\"안전배송\", u\"당일\", u\"배송\", u\"발송\", u\"빠른\",\n",
    "              u\"신한카드\", u\"BC카드\", u\"KB국민카드\", u\"국민카드\", u\"롯데카드\", u\"KB카드\", u\"현대카드\", u\"삼성카드\", u\"일까지\"]\n",
    "symbols = [\"[\",\"]\",\"(\",\")\", \"+\", \"-\", \"/\", \"?\", \"~\", \"*\", u\"☆\", u\"★\", u\"●\", u\"♥\", u\"■\", u\"▶\", u\"◀\", u\"↑\"]\n",
    "ambg_words = [u\"해외\", u\"구매대행\"]\n",
    "\n",
    "start = 0\n",
    "length = 1\n",
    "remove_ambg = True\n",
    "\n",
    "# define concatenate function\n",
    "def concate(list1, list2) :\n",
    "    for each in list2:\n",
    "        list1.append(each)\n",
    "    return list1\n",
    "\n",
    "remove_list = concate(stop_words, symbols)\n",
    "if remove_ambg:\n",
    "    remove_list = concate(remove_list,ambg_words)\n",
    "    \n",
    "def removeStopWords(word) :\n",
    "     # replace\n",
    "    for before, after in mapping.iteritems():\n",
    "        word = word.replace(before, after)\n",
    "    #remove\n",
    "    for each in remove_list :\n",
    "        word = word.replace(each,\" \")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define splitMorph using konlpy\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.utils import pprint\n",
    "kkma = Twitter()\n",
    "\n",
    "def splitMorph(word) :\n",
    "    morphs = kkma.pos(word)\n",
    "    words = \"\"\n",
    "    for morph in morphs :\n",
    "        word = morph[0]\n",
    "        words += \" \" + word\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n"
     ]
    }
   ],
   "source": [
    "# read json results of samples\n",
    "list_caffe_samples = joblib.load('list_caffe_samples.dat')\n",
    "list_caffe_test = joblib.load('list_caffe_test.dat')\n",
    "\n",
    "is_test = True\n",
    "\n",
    "if is_test :\n",
    "    list_caffe = list_caffe_test\n",
    "else :\n",
    "    list_caffe = list_caffe_samples\n",
    "print len(list_caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bottle v0.12.9 server starting up (using WSGIRefServer())...\n",
      "Listening on http://0.0.0.0:8887/\n",
      "Hit Ctrl-C to quit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classify called\n",
      "0 saved\n",
      " ' 안녕 안녕 안녕 안녕 ' website BandAid packet cashmachine envelope website computer machine device container\n",
      "디지털/가전;PC부품;CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.99.1 - - [22/Aug/2016 15:35:17] \"GET /classify?name=%27%EC%95%88%EB%85%95%EC%95%88%EB%85%95%20%EC%95%88%EB%85%95%20%EC%95%88%EB%85%95%27&img=%27asdasdadsad%27 HTTP/1.1\" 200 62\n",
      "192.168.99.1 - - [22/Aug/2016 15:35:17] \"GET /favicon.ico HTTP/1.1\" 404 747\n"
     ]
    }
   ],
   "source": [
    "# server for 206 samples tests\n",
    "\n",
    "from bottle import route, run, template,request,get, post\n",
    "import  time\n",
    "from threading import  Condition\n",
    "_CONDITION = Condition()\n",
    "\n",
    "# initialize size\n",
    "size = 0\n",
    "joblib.dump(size,'size.dat')\n",
    "\n",
    "@route('/classify')\n",
    "def classify():\n",
    "    print \"classify called\"\n",
    "    img = request.GET.get('img','')\n",
    "    name = request.GET.get('name', '').decode('utf-8')\n",
    "    \n",
    "    name = removeStopWords(name)\n",
    "    name = splitMorph(name)\n",
    "    \n",
    "    # read size\n",
    "    size = joblib.load('size.dat')\n",
    "    \n",
    "    # append caffe result\n",
    "    res = list_caffe[size]['result']\n",
    "    if res[0] :\n",
    "        #for each in res[1] :\n",
    "        #    name += \" \" + each[0].replace(\" \", \"\")\n",
    "        for each in res[2] :\n",
    "            name += \" \" + each[0].replace(\" \", \"\")\n",
    "    \n",
    "    vec = vectorizer.transform([name])\n",
    "    p = clf.predict(vec)\n",
    "    pred = p[0]\n",
    "    \n",
    "    # update and store size\n",
    "    if size % 100 == 0:\n",
    "        print \"%d saved\" % size\n",
    "        print name\n",
    "        print cate_id_name_dict[pred]\n",
    "    \n",
    "    size = size + 1;\n",
    "    joblib.dump(size,'size.dat')\n",
    "    \n",
    "    return {'cate':cate_id_name_dict[pred]}\n",
    "\n",
    "\n",
    "run(host='0.0.0.0', port=8887)\n",
    "#  http://somaeval.hoot.co.kr:8884/eval?url=http://  :8887&mode=all&name=oyj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " * 추후 여기 docker 에서 뭔가 python package 설치할게 있으면 \n",
    " * /opt/conda/bin/pip2 install bottle 이런식으로 설치 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
